https://vcg.seas.harvard.edu/files/pfister/files/infovis_submission251-camera.pdf

This paper investigats how visualizations are recognized and recalled. It labels a dataset of 393 visualizations and analyzed the eye movements of 33 participants as well as thousands of participant-generated text descriptions of the visualizations. These information is used to determine what components of a visualization attract people’s attention, and what information is encoded into memory. The findings quantitatively support many conventional qualitative design guidelines, including that:

 (1) titles and supporting text should convey the message of a visualization. Titles and text attract people’s attention, are dwelled upon during encoding, and correspondingly contribute to recognition and recall. People spend the most amount of time looking at the text in a visualization, and more specifically, the title. If a title is not present, or is in an unexpected location (i.e., not at the top of the visualization), other textual elements receive attention. As exhibited by these results, the content of a title has a significant impact on what a person will take away from, and later recall, about a visualization.
 
(2) if used appropriately, pictograms do not interfere with understanding and can improve recognition. Visualizations that contain pictograms tend to be better recognized and described. Pictograms can often serve as visual hooks into memory, allowing a visualization to be retrieved from memory more effectively. If designed well, pictograms can help convey the message of the visualization, as an alternative, and addition to text. 

(3) redundancy helps effectively communicate the message. Importantly, the paper shows that visualizations that are memorable “at-a-glance” have memorable content. Visualizations that are most memorable “at-a-glance” are those that can be quickly retrieved from memory (i.e., require less eye movements to recognize the visualization). Importantly, when these visualizations are retrieved from memory, many details of the visualization are retrieved as well. Thus, participant-generated descriptions tend to be higher quality for these visualizations. 
